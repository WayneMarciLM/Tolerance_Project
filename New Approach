import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

def advanced_office_utilization_analysis(badge_df):
    """
    Comprehensive analysis of office space utilization across multiple dimensions
    
    Args:
        badge_df (pd.DataFrame): Detailed badge entry dataframe
    
    Returns:
        dict: Comprehensive analysis results
    """
    # Ensure correct date parsing
    badge_df['DATE'] = pd.to_datetime(badge_df['DATE'])
    badge_df['HIRE_DATE'] = pd.to_datetime(badge_df['HIRE_DATE'])
    
    # Convert HOME_ALLOCATION_PERCENT to float explicitly
    badge_df['HOME_ALLOCATION_PERCENT'] = badge_df['HOME_ALLOCATION_PERCENT'].astype(float)
    
    # 1. Daily Utilization by Segment Description
    org_utilization = {}
    try:
        org_utilization['SEGMENT_DESCRIPTION'] = (
            badge_df.groupby(['SEGMENT_DESCRIPTION', 'DATE'])['EMPLOYEE_NUMBER']
            .nunique()
            .groupby('SEGMENT_DESCRIPTION')
            .agg(['mean', 'max', 'min'])
            .rename(columns={'mean': 'avg_daily_employees', 'max': 'peak_employees', 'min': 'min_employees'})
        )
    except Exception as e:
        print(f"Error analyzing SEGMENT_DESCRIPTION: {e}")
    
    # 2. Allocation Compliance Analysis
    def allocation_compliance_analysis(df):
        try:
            # Ensure we're working with a copy and drop any rows with missing critical data
            df_clean = df.dropna(subset=['EMPLOYEE_NUMBER', 'HOME_ALLOCATION_PERCENT', 'DATE'])
            
            # Aggregate data by employee
            allocation_compliance = df_clean.groupby('EMPLOYEE_NUMBER').agg({
                'DATE': 'count',
                'HOME_ALLOCATION_PERCENT': 'first'
            }).rename(columns={'DATE': 'badge_frequency'})
            
            # Ensure all values are float
            allocation_compliance['badge_frequency'] = allocation_compliance['badge_frequency'].astype(float)
            allocation_compliance['HOME_ALLOCATION_PERCENT'] = allocation_compliance['HOME_ALLOCATION_PERCENT'].astype(float)
            
            # Calculate compliance metrics
            allocation_compliance['expected_badge_days'] = (
                allocation_compliance['HOME_ALLOCATION_PERCENT'] * 
                len(df) / 100  # Scale expected days based on total dataset
            )
            
            allocation_compliance['compliance_score'] = np.abs(
                allocation_compliance['badge_frequency'] - 
                allocation_compliance['expected_badge_days']
            )
            
            return {
                'overall_compliance_correlation': allocation_compliance['badge_frequency'].corr(allocation_compliance['HOME_ALLOCATION_PERCENT']),
                'compliance_distribution': allocation_compliance['compliance_score'].describe().to_dict(),
                'detailed_compliance_analysis': allocation_compliance
            }
        except Exception as e:
            print(f"Allocation compliance analysis error: {e}")
            return {}
    
    # 3. Temporal Utilization Analysis
    def temporal_utilization_analysis(df):
        try:
            # Day of week analysis
            df['day_of_week'] = df['DATE'].dt.day_name()
            day_of_week_utilization = (
                df.groupby('day_of_week')['EMPLOYEE_NUMBER']
                .nunique()
                .reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])
            )
            
            # Time since hire analysis
            df['days_since_hire'] = (df['DATE'] - df['HIRE_DATE']).dt.days
            hire_period_utilization = df.groupby(pd.cut(df['days_since_hire'], 
                bins=[0, 90, 180, 365, np.inf], 
                labels=['0-3 months', '3-6 months', '6-12 months', '1+ years']
            ))['EMPLOYEE_NUMBER'].nunique()
            
            return {
                'day_of_week_utilization': day_of_week_utilization,
                'hire_period_utilization': hire_period_utilization
            }
        except Exception as e:
            print(f"Error in temporal utilization analysis: {e}")
            return {}
    
    # 4. Predictive Utilization Modeling
    def predictive_utilization_model(df):
        try:
            # Prepare features for predictive analysis
            feature_columns = [
                'HOME_ALLOCATION_PERCENT', 'GRADE_EQUIVALENT', 
                'CURRENT_DAYS_OF_PLACEMENT'
            ]
            
            # Aggregate features and badge frequency by employee
            employee_features = df.groupby('EMPLOYEE_NUMBER').agg({
                'HOME_ALLOCATION_PERCENT': 'first',
                'GRADE_EQUIVALENT': 'first',
                'CURRENT_DAYS_OF_PLACEMENT': 'first',
                'DATE': 'count'
            }).rename(columns={'DATE': 'badge_frequency'})
            
            # Convert to float
            for col in feature_columns + ['badge_frequency']:
                employee_features[col] = employee_features[col].astype(float)
            
            # One-hot encode management level
            management_dummies = pd.get_dummies(df.groupby('EMPLOYEE_NUMBER')['MANAGEMENT_LEVEL'].first(), prefix='mgmt')
            
            # Combine features
            X = pd.concat([
                employee_features[feature_columns], 
                management_dummies
            ], axis=1)
            y = employee_features['badge_frequency']
            
            # Create a pipeline to handle missing values and scaling
            pipeline = Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler()),
                ('regressor', LinearRegression())
            ])
            
            # Split and model
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            pipeline.fit(X_train, y_train)
            
            return {
                'model_r2_score': r2_score(y_test, pipeline.predict(X_test)),
                'model_mse': mean_squared_error(y_test, pipeline.predict(X_test)),
                'feature_importances': dict(zip(X.columns, pipeline.named_steps['regressor'].coef_))
            }
        except Exception as e:
            print(f"Error in predictive utilization model: {e}")
            return {}
    
    # Combine all analyses
    analysis_results = {
        'organizational_utilization': org_utilization,
        'allocation_compliance': allocation_compliance_analysis(badge_df),
        'temporal_patterns': temporal_utilization_analysis(badge_df),
        'predictive_model': predictive_utilization_model(badge_df)
    }
    
    return analysis_results

# The rest of the script remains the same as in the previous version

# Main execution
try:
    # Run the analysis
    results = advanced_office_utilization_analysis(badge_df)
    
    # Generate visualizations
    visualize_advanced_analysis(results)
    
    # Generate and print the report
    report = generate_advanced_utilization_report(results)
    print(report)
except Exception as e:
    print(f"An error occurred during analysis: {e}")
    import traceback
    traceback.print_exc()
