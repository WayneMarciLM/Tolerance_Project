results:

Error in allocation compliance analysis: 'float' object has no attribute 'shape'
Error in predictive utilization model: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

# Advanced Office Space Utilization Report

## Organizational Utilization Insights
### LEVEL_1
- Average Daily Employees: 46.09
- Peak Employees: 109.50
- Minimum Employees: 1.00

### LEVEL_2
- Average Daily Employees: 8.80
- Peak Employees: 24.25
- Minimum Employees: 1.00

### LEVEL_3
- Average Daily Employees: 3.41
- Peak Employees: 10.17
- Minimum Employees: 1.02

### LEVEL_4
- Average Daily Employees: 2.74
- Peak Employees: 7.72
- Minimum Employees: 1.03

### JOB_FAMILY
- Average Daily Employees: 6.72
- Peak Employees: 17.28
- Minimum Employees: 1.05

### SEGMENT_DESCRIPTION
- Average Daily Employees: 75.71
- Peak Employees: 167.50
- Minimum Employees: 1.00

### MANAGEMENT_LEVEL
- Average Daily Employees: 1.18
- Peak Employees: 1.38
- Minimum Employees: 1.00

## Temporal Utilization Patterns
### Day of Week Utilization
- Monday: 2087
- Tuesday: 3102
- Wednesday: 3183
- Thursday: 2894
- Friday: 1631

### Utilization by Tenure
- 0-3 months: 132
- 3-6 months: 67
- 6-12 months: 108
- 1+ years: 3594


## Key Recommendations
1. Analyze organizational-level utilization patterns
2. Review home allocation compliance
3. Investigate temporal utilization trends
4. Use predictive model insights for space planning



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

def advanced_office_utilization_analysis(badge_df):
    """
    Comprehensive analysis of office space utilization across multiple dimensions
    
    Args:
        badge_df (pd.DataFrame): Detailed badge entry dataframe
    
    Returns:
        dict: Comprehensive analysis results
    """
    # Ensure correct date parsing
    badge_df['DATE'] = pd.to_datetime(badge_df['DATE'])
    badge_df['HIRE_DATE'] = pd.to_datetime(badge_df['HIRE_DATE'])
    
    # 1. Daily Utilization by Organizational Dimensions
    org_levels = ['LEVEL_1', 'LEVEL_2', 'LEVEL_3', 'LEVEL_4']
    
    org_utilization = {}
    for level in org_levels:
        try:
            org_utilization[level] = (
                badge_df.groupby([level, 'DATE'])['EMPLOYEE_NUMBER']
                .nunique()
                .groupby(level)
                .agg(['mean', 'max', 'min'])
                .rename(columns={'mean': 'avg_daily_employees', 'max': 'peak_employees', 'min': 'min_employees'})
            )
        except Exception as e:
            print(f"Error analyzing {level}: {e}")
    
    # 2. Allocation Compliance Analysis
    def allocation_compliance_analysis(df):
        try:
            # Handle potential missing values
            df_clean = df.dropna(subset=['EMPLOYEE_NUMBER', 'HOME_ALLOCATION_PERCENT'])
            
            # Calculate badge frequency per employee
            employee_badge_freq = df_clean.groupby('EMPLOYEE_NUMBER')['DATE'].count()
            
            # Link with home allocation percentage
            allocation_compliance = pd.DataFrame({
                'badge_frequency': employee_badge_freq,
                'home_allocation_percent': df_clean.groupby('EMPLOYEE_NUMBER')['HOME_ALLOCATION_PERCENT'].first()
            })
            
            # Calculate correlation and compliance score
            allocation_compliance['expected_badge_days'] = allocation_compliance['home_allocation_percent'] * 100
            allocation_compliance['compliance_score'] = np.abs(allocation_compliance['badge_frequency'] - allocation_compliance['expected_badge_days'])
            
            return {
                'overall_compliance_correlation': allocation_compliance['badge_frequency'].corr(allocation_compliance['home_allocation_percent']),
                'compliance_distribution': allocation_compliance['compliance_score'].describe(),
                'detailed_compliance_analysis': allocation_compliance
            }
        except Exception as e:
            print(f"Error in allocation compliance analysis: {e}")
            return {}
    
    # 3. Temporal Utilization Analysis
    def temporal_utilization_analysis(df):
        try:
            # Day of week analysis
            df['day_of_week'] = df['DATE'].dt.day_name()
            day_of_week_utilization = (
                df.groupby('day_of_week')['EMPLOYEE_NUMBER']
                .nunique()
                .reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])
            )
            
            # Time since hire analysis
            df['days_since_hire'] = (df['DATE'] - df['HIRE_DATE']).dt.days
            hire_period_utilization = df.groupby(pd.cut(df['days_since_hire'], 
                bins=[0, 90, 180, 365, np.inf], 
                labels=['0-3 months', '3-6 months', '6-12 months', '1+ years']
            ))['EMPLOYEE_NUMBER'].nunique()
            
            return {
                'day_of_week_utilization': day_of_week_utilization,
                'hire_period_utilization': hire_period_utilization
            }
        except Exception as e:
            print(f"Error in temporal utilization analysis: {e}")
            return {}
    
    # 4. Predictive Utilization Modeling
    def predictive_utilization_model(df):
        try:
            # Prepare features for predictive analysis
            feature_columns = [
                'HOME_ALLOCATION_PERCENT', 'GRADE_EQUIVALENT', 
                'CURRENT_DAYS_OF_PLACEMENT'
            ]
            
            # Aggregate features and badge frequency by employee
            employee_features = df.groupby('EMPLOYEE_NUMBER').agg({
                'HOME_ALLOCATION_PERCENT': 'first',
                'GRADE_EQUIVALENT': 'first',
                'CURRENT_DAYS_OF_PLACEMENT': 'first',
                'DATE': 'count'
            }).rename(columns={'DATE': 'badge_frequency'})
            
            # One-hot encode management level
            management_dummies = pd.get_dummies(df.groupby('EMPLOYEE_NUMBER')['MANAGEMENT_LEVEL'].first(), prefix='mgmt')
            
            # Combine features
            X = pd.concat([
                employee_features[feature_columns], 
                management_dummies
            ], axis=1)
            y = employee_features['badge_frequency']
            
            # Create a pipeline to handle missing values and scaling
            pipeline = Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler()),
                ('regressor', LinearRegression())
            ])
            
            # Split and model
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            pipeline.fit(X_train, y_train)
            
            return {
                'model_r2_score': r2_score(y_test, pipeline.predict(X_test)),
                'model_mse': mean_squared_error(y_test, pipeline.predict(X_test)),
                'feature_importances': dict(zip(X.columns, pipeline.named_steps['regressor'].coef_))
            }
        except Exception as e:
            print(f"Error in predictive utilization model: {e}")
            return {}
    
    # Combine all analyses
    analysis_results = {
        'organizational_utilization': org_utilization,
        'allocation_compliance': allocation_compliance_analysis(badge_df),
        'temporal_patterns': temporal_utilization_analysis(badge_df),
        'predictive_model': predictive_utilization_model(badge_df)
    }
    
    return analysis_results

def visualize_advanced_analysis(results):
    """
    Create comprehensive visualizations for the advanced analysis
    
    Args:
        results (dict): Analysis results from advanced_office_utilization_analysis
    """
    plt.figure(figsize=(15, 10))
    
    # 1. Organizational Utilization Heatmap (Only LEVEL_1-4)
    plt.subplot(2, 2, 1)
    org_levels = list(results['organizational_utilization'].keys())
    
    # Prepare data for heatmap
    utilization_matrix = pd.DataFrame({
        level: results['organizational_utilization'][level]['avg_daily_employees'] 
        for level in org_levels
    })
    
    # Ensure the matrix is not empty
    if not utilization_matrix.empty:
        try:
            sns.heatmap(utilization_matrix, cmap='YlGnBu', annot=True, fmt='.2f')
            plt.title('Organizational Level Utilization')
            plt.xlabel('Organizational Levels')
            plt.ylabel('Avg Daily Employees')
            plt.xticks(rotation=45, ha='right')
        except Exception as e:
            print(f"Error creating heatmap: {e}")
    
    # 2. Allocation Compliance Distribution
    plt.subplot(2, 2, 2)
    if 'detailed_compliance_analysis' in results['allocation_compliance']:
        compliance_df = results['allocation_compliance']['detailed_compliance_analysis']
        plt.scatter(
            compliance_df['home_allocation_percent'], 
            compliance_df['badge_frequency'], 
            c=compliance_df['compliance_score'], 
            cmap='viridis'
        )
        plt.colorbar(label='Compliance Score')
        plt.title('Home Allocation vs Badge Frequency')
        plt.xlabel('Home Allocation %')
        plt.ylabel('Badge Frequency')
    
    # 3. Day of Week Utilization
    plt.subplot(2, 2, 3)
    if 'day_of_week_utilization' in results['temporal_patterns']:
        day_utilization = results['temporal_patterns']['day_of_week_utilization']
        day_utilization.plot(kind='bar')
        plt.title('Employee Utilization by Day of Week')
        plt.xlabel('Day of Week')
        plt.ylabel('Unique Employees')
        plt.xticks(rotation=45)
    
    # 4. Hire Period Utilization
    plt.subplot(2, 2, 4)
    if 'hire_period_utilization' in results['temporal_patterns']:
        hire_utilization = results['temporal_patterns']['hire_period_utilization']
        hire_utilization.plot(kind='pie', autopct='%1.1f%%')
        plt.title('Employee Utilization by Tenure')
    
    plt.tight_layout()
    plt.show()

def generate_advanced_utilization_report(results):
    """
    Generate a comprehensive report of advanced office utilization analysis
    
    Args:
        results (dict): Analysis results from advanced_office_utilization_analysis
    
    Returns:
        str: Detailed markdown report
    """
    report = "# Advanced Office Space Utilization Report\n\n"
    
    # Organizational Utilization
    report += "## Organizational Utilization Insights\n"
    for level, utilization in results['organizational_utilization'].items():
        report += f"### {level}\n"
        report += f"- Average Daily Employees: {utilization['avg_daily_employees'].mean():.2f}\n"
        report += f"- Peak Employees: {utilization['peak_employees'].mean():.2f}\n"
        report += f"- Minimum Employees: {utilization['min_employees'].mean():.2f}\n\n"
    
    # Allocation Compliance
    if results['allocation_compliance']:
        report += "## Home Allocation Compliance\n"
        report += f"- Correlation: {results['allocation_compliance'].get('overall_compliance_correlation', 'N/A')}\n"
        
        compliance_dist = results['allocation_compliance'].get('compliance_distribution', {})
        for stat, value in compliance_dist.items():
            report += f"- {stat.capitalize()}: {value:.2f}\n"
        report += "\n"
    
    # Temporal Patterns
    if results['temporal_patterns']:
        report += "## Temporal Utilization Patterns\n"
        
        day_util = results['temporal_patterns'].get('day_of_week_utilization', {})
        report += "### Day of Week Utilization\n"
        for day, utilization in day_util.items():
            report += f"- {day}: {utilization}\n"
        
        hire_util = results['temporal_patterns'].get('hire_period_utilization', {})
        report += "\n### Utilization by Tenure\n"
        for period, utilization in hire_util.items():
            report += f"- {period}: {utilization}\n"
        report += "\n"
    
    # Predictive Model
    if results['predictive_model']:
        report += "## Predictive Utilization Model\n"
        report += f"- R² Score: {results['predictive_model'].get('model_r2_score', 'N/A')}\n"
        report += f"- Mean Squared Error: {results['predictive_model'].get('model_mse', 'N/A')}\n"
        
        feature_importance = results['predictive_model'].get('feature_importances', {})
        report += "\n### Feature Importances\n"
        for feature, importance in sorted(feature_importance.items(), key=lambda x: abs(x[1]), reverse=True)[:5]:
            report += f"- {feature}: {importance:.4f}\n"
    
    report += "\n## Key Recommendations\n"
    report += "1. Analyze organizational-level utilization patterns\n"
    report += "2. Review home allocation compliance\n"
    report += "3. Investigate temporal utilization trends\n"
    report += "4. Use predictive model insights for space planning\n"
    
    return report

# Main execution
try:
    # Run the analysis
    results = advanced_office_utilization_analysis(badge_df)
    
    # Generate visualizations
    visualize_advanced_analysis(results)
    
    # Generate and print the report
    report = generate_advanced_utilization_report(results)
    print(report)
except Exception as e:
    print(f"An error occurred during analysis: {e}")
    import traceback
    traceback.print_exc()
