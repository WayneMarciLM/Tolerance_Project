import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

def advanced_office_utilization_analysis(badge_df):
    """
    Comprehensive analysis of office space utilization across multiple dimensions
    
    Args:
        badge_df (pd.DataFrame): Detailed badge entry dataframe
    
    Returns:
        dict: Comprehensive analysis results
    """
    # Ensure correct date parsing
    badge_df['DATE'] = pd.to_datetime(badge_df['DATE'])
    badge_df['HIRE_DATE'] = pd.to_datetime(badge_df['HIRE_DATE'])
    
    # Convert HOME_ALLOCATION_PERCENT to float explicitly
    badge_df['HOME_ALLOCATION_PERCENT'] = badge_df['HOME_ALLOCATION_PERCENT'].astype(float)
    
    # 1. Daily Utilization by Segment Description
    org_utilization = {}
    try:
        org_utilization['SEGMENT_DESCRIPTION'] = (
            badge_df.groupby(['SEGMENT_DESCRIPTION', 'DATE'])['EMPLOYEE_NUMBER']
            .nunique()
            .groupby('SEGMENT_DESCRIPTION')
            .agg(['mean', 'max', 'min'])
            .rename(columns={'mean': 'avg_daily_employees', 'max': 'peak_employees', 'min': 'min_employees'})
        )
    except Exception as e:
        print(f"Error analyzing SEGMENT_DESCRIPTION: {e}")
    
    # 2. Allocation Compliance Analysis
    def allocation_compliance_analysis(df):
        try:
            # Ensure we're working with a copy and drop any rows with missing critical data
            df_clean = df.dropna(subset=['EMPLOYEE_NUMBER', 'HOME_ALLOCATION_PERCENT', 'DATE'])
            
            # Aggregate data by employee
            allocation_compliance = df_clean.groupby('EMPLOYEE_NUMBER').agg({
                'DATE': 'count',
                'HOME_ALLOCATION_PERCENT': 'first'
            }).rename(columns={'DATE': 'badge_frequency'})
            
            # Ensure all values are float
            allocation_compliance['badge_frequency'] = allocation_compliance['badge_frequency'].astype(float)
            allocation_compliance['HOME_ALLOCATION_PERCENT'] = allocation_compliance['HOME_ALLOCATION_PERCENT'].astype(float)
            
            # Calculate compliance metrics
            allocation_compliance['expected_badge_days'] = (
                allocation_compliance['HOME_ALLOCATION_PERCENT'] * 
                len(df) / 100  # Scale expected days based on total dataset
            )
            
            allocation_compliance['compliance_score'] = np.abs(
                allocation_compliance['badge_frequency'] - 
                allocation_compliance['expected_badge_days']
            )
            
            return {
                'overall_compliance_correlation': allocation_compliance['badge_frequency'].corr(allocation_compliance['HOME_ALLOCATION_PERCENT']),
                'compliance_distribution': allocation_compliance['compliance_score'].describe().to_dict(),
                'detailed_compliance_analysis': allocation_compliance
            }
        except Exception as e:
            print(f"Allocation compliance analysis error: {e}")
            return {}
    
    # 3. Temporal Utilization Analysis
    def temporal_utilization_analysis(df):
        try:
            # Day of week analysis
            df['day_of_week'] = df['DATE'].dt.day_name()
            day_of_week_utilization = (
                df.groupby('day_of_week')['EMPLOYEE_NUMBER']
                .nunique()
                .reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])
            )
            
            # Time since hire analysis
            df['days_since_hire'] = (df['DATE'] - df['HIRE_DATE']).dt.days
            hire_period_utilization = df.groupby(pd.cut(df['days_since_hire'], 
                bins=[0, 90, 180, 365, np.inf], 
                labels=['0-3 months', '3-6 months', '6-12 months', '1+ years']
            ))['EMPLOYEE_NUMBER'].nunique()
            
            return {
                'day_of_week_utilization': day_of_week_utilization,
                'hire_period_utilization': hire_period_utilization
            }
        except Exception as e:
            print(f"Error in temporal utilization analysis: {e}")
            return {}
    
    # 4. Predictive Utilization Modeling
    def predictive_utilization_model(df):
        try:
            # Prepare features for predictive analysis
            feature_columns = [
                'HOME_ALLOCATION_PERCENT', 'GRADE_EQUIVALENT', 
                'CURRENT_DAYS_OF_PLACEMENT'
            ]
            
            # Aggregate features and badge frequency by employee
            employee_features = df.groupby('EMPLOYEE_NUMBER').agg({
                'HOME_ALLOCATION_PERCENT': 'first',
                'GRADE_EQUIVALENT': 'first',
                'CURRENT_DAYS_OF_PLACEMENT': 'first',
                'DATE': 'count'
            }).rename(columns={'DATE': 'badge_frequency'})
            
            # Convert to float
            for col in feature_columns + ['badge_frequency']:
                employee_features[col] = employee_features[col].astype(float)
            
            # One-hot encode management level
            management_dummies = pd.get_dummies(df.groupby('EMPLOYEE_NUMBER')['MANAGEMENT_LEVEL'].first(), prefix='mgmt')
            
            # Combine features
            X = pd.concat([
                employee_features[feature_columns], 
                management_dummies
            ], axis=1)
            y = employee_features['badge_frequency']
            
            # Create a pipeline to handle missing values and scaling
            pipeline = Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler()),
                ('regressor', LinearRegression())
            ])
            
            # Split and model
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            pipeline.fit(X_train, y_train)
            
            return {
                'model_r2_score': r2_score(y_test, pipeline.predict(X_test)),
                'model_mse': mean_squared_error(y_test, pipeline.predict(X_test)),
                'feature_importances': dict(zip(X.columns, pipeline.named_steps['regressor'].coef_))
            }
        except Exception as e:
            print(f"Error in predictive utilization model: {e}")
            return {}
    
    # Combine all analyses
    analysis_results = {
        'organizational_utilization': org_utilization,
        'allocation_compliance': allocation_compliance_analysis(badge_df),
        'temporal_patterns': temporal_utilization_analysis(badge_df),
        'predictive_model': predictive_utilization_model(badge_df)
    }
    
    return analysis_results

# The rest of the script remains the same as in the previous version

# Main execution
try:
    # Run the analysis
    results = advanced_office_utilization_analysis(badge_df)
    
    # Generate visualizations
    visualize_advanced_analysis(results)
    
    # Generate and print the report
    report = generate_advanced_utilization_report(results)
    print(report)
except Exception as e:
    print(f"An error occurred during analysis: {e}")
    import traceback
    traceback.print_exc()



---------------------------


import pandas as pd
import numpy as np

def seat_utilization_analysis(badge_df):
    """
    Analyze badge usage to determine seat requirements based on percentiles.
    
    Args:
        badge_df (pd.DataFrame): Detailed badge entry dataframe
    
    Returns:
        dict: Analysis results regarding seat requirements and usage.
    """
    # Ensure correct date parsing
    badge_df['DATE'] = pd.to_datetime(badge_df['DATE'])
    
    # 1. Calculate daily usage counts
    daily_usage = badge_df.groupby('DATE')['EMPLOYEE_NUMBER'].nunique()
    
    # 2. Determine required seats based on percentiles
    percentiles = [95, 90, 85, 80, 75]
    seat_requirements = {}
    
    for percentile in percentiles:
        # Calculate the seat requirement based on the specified percentile
        required_seats = np.percentile(daily_usage, percentile)
        over_capacity_days = (daily_usage > required_seats).sum()
        
        seat_requirements[percentile] = {
            'required_seats': int(required_seats),
            'days_over_capacity': over_capacity_days
        }
    
    # 3. Analyze trends over time
    def analyze_trends(daily_usage):
        trends = {
            'average_daily_usage': daily_usage.mean(),
            'max_daily_usage': daily_usage.max(),
            'min_daily_usage': daily_usage.min(),
            'std_daily_usage': daily_usage.std()
        }
        return trends

    trends = analyze_trends(daily_usage)
    
    # 4. Determine utilization by day of week
    badge_df['day_of_week'] = badge_df['DATE'].dt.day_name()
    week_day_utilization = badge_df.groupby('day_of_week')['EMPLOYEE_NUMBER'].nunique().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])

    # 5. Identify high usage days (top 5 days)
    top_usage_days = daily_usage.nlargest(5)

    # Combine all results into a dictionary
    analysis_results = {
        'seat_requirements': seat_requirements,
        'trends': trends,
        'week_day_utilization': week_day_utilization,
        'top_usage_days': top_usage_days
    }
    
    return analysis_results

# Main execution
try:
    # Assuming badge_df is already defined and contains the necessary data
    results = seat_utilization_analysis(badge_df)
    
    # Display results
    print("Seat Utilization Analysis Results:")
    print(results)
except Exception as e:
    print(f"An error occurred during analysis: {e}")
    import traceback
    traceback.print_exc()


---------------------------------

# Main execution
if __name__ == "__main__":
    try:
        # Assuming badge_df is already defined and contains the necessary data
        input_seat_count = int(input("Enter the current number of seats: "))
        vibrancy_percent = float(input("Enter the desired vibrancy percentage (0-100): "))
        
        results = scenario_analysis(badge_df, input_seat_count, vibrancy_percent)
        
        # Display results
        print("Scenario Analysis Results:")
        print(f"Input Seat Count: {results['input_seat_count']}")
        print(f"Total Days Over Capacity: {results['over_capacity_days']}")
        
        # Only show the count of over capacity days instead of the dates
        if results['over_capacity_days'] > 0:
            print(f"Dates Over Capacity: {len(results['over_capacity_dates'])} days total")
        else:
            print("Dates Over Capacity: None")
        
        print(f"Total Days Feeling Empty: {results['empty_days']}")
        
        # Only show the count of empty days instead of the dates
        if results['empty_days'] > 0:
            print(f"Dates Feeling Empty: {len(results['empty_dates'])} days total")
        else:
            print("Dates Feeling Empty: None")
        
        # Required seats analysis
        for percentile, data in results['required_seats'].items():
            print(f"{percentile}th Percentile - Required Seats: {data['required_seats']}, Days Over Capacity: {data['days_over_capacity']}")
    except Exception as e:
        print(f"An error occurred during analysis: {e}")
        import traceback
        traceback.print_exc()
